{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    " \n",
    " \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 19,466\n",
      "Trainable params: 19,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dropout(0.5),\n",
    "#         layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        keras.layers.GlobalMaxPooling2D(),\n",
    "        tf.keras.layers.Dense(10, activation='softmax'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "422/422 [==============================] - 2s 4ms/step - loss: 0.8587 - accuracy: 0.7755 - val_loss: 0.2419 - val_accuracy: 0.9350\n",
      "Epoch 2/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.2263 - accuracy: 0.9330 - val_loss: 0.1616 - val_accuracy: 0.9517\n",
      "Epoch 3/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.1677 - accuracy: 0.9489 - val_loss: 0.1485 - val_accuracy: 0.9545\n",
      "Epoch 4/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.1395 - accuracy: 0.9571 - val_loss: 0.1257 - val_accuracy: 0.9618\n",
      "Epoch 5/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.1226 - accuracy: 0.9624 - val_loss: 0.1087 - val_accuracy: 0.9673\n",
      "Epoch 6/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.1095 - accuracy: 0.9661 - val_loss: 0.1066 - val_accuracy: 0.9667\n",
      "Epoch 7/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9685 - val_loss: 0.0953 - val_accuracy: 0.9695\n",
      "Epoch 8/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.0933 - accuracy: 0.9708 - val_loss: 0.0844 - val_accuracy: 0.9737\n",
      "Epoch 9/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.0882 - accuracy: 0.9728 - val_loss: 0.0930 - val_accuracy: 0.9717\n",
      "Epoch 10/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.0794 - accuracy: 0.9756 - val_loss: 0.0908 - val_accuracy: 0.9715\n",
      "Epoch 11/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.0757 - accuracy: 0.9758 - val_loss: 0.0715 - val_accuracy: 0.9780\n",
      "Epoch 12/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.0703 - accuracy: 0.9778 - val_loss: 0.0692 - val_accuracy: 0.9782\n",
      "Epoch 13/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.0684 - accuracy: 0.9791 - val_loss: 0.0655 - val_accuracy: 0.9795\n",
      "Epoch 14/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.0643 - accuracy: 0.9801 - val_loss: 0.0738 - val_accuracy: 0.9770\n",
      "Epoch 15/15\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.0605 - accuracy: 0.9815 - val_loss: 0.0653 - val_accuracy: 0.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb3c019f6d8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.06948108226060867\n",
      "Test accuracy: 0.9796000123023987\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_output = tf.keras.backend.function([model.layers[0].input],\n",
    "                                       [model.layers[-3].output, model.layers[-1].output])\n",
    "[conv_outputs, predictions] = get_output(x_train[index:index+1])\n",
    "class_weights = model.layers[-1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conv_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for num, idx in enumerate(np.argmax(predictions,axis=1)):\n",
    "    cam = tf.matmul(np.expand_dims(class_weights[:,idx],axis = 0),\n",
    "                    np.transpose(np.reshape(conv_outputs[num],(11*11,64))))\n",
    "    cam = tf.keras.backend.eval(cam)\n",
    "    output.append(cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb447cda208>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(np.reshape(output[0][0], (11, 11)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb447c40358>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(x_train[index], (28, 28)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(x_train[index:index+1])\n",
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_p36] *",
   "language": "python",
   "name": "conda-env-tensorflow2_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
